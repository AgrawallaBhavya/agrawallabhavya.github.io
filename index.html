<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Bhavya Agrawalla</title>

    <meta name="author" content="Bhavya Agrawalla">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Bhavya Agrawalla
                </p>
                <p>I am Bhavya Agrawalla, second-year CS PhD student at CMU advised by Prof. <a href="https://aviralkumar2907.github.io/">Aviral Kumar</a>. Previously I was a Math and CS undergrad at MIT (2021-24) and IISc Bangalore (2020 - 21).
                </p>
                <p>
                  My research interests are in deep reinforcement learning and statistics. 
                </p>
                <p>
                  At MIT, I have been extremely lucky to work with-
                </p>
                
                <ul>
                <li>Prof. <a href="https://math.mit.edu/~hrm/">Haynes Miller</a> from the MIT Math Department on homological algebra,</li>
                 <li>Prof. <a href="https://sites.google.com/view/promit-ghosal/home">Promit Ghosal</a> from Brandeis Math and Prof. <a href="https://sites.google.com/view/kriznakumar/home">Krishnakumar Balasubramaniam</a> from UC Davis Statistics on learning theory, statistics and optimisation,</li> 
                  <li>Prof. <a href="https://www.media.mit.edu/people/raskar/overview/">Ramesh Raskar's</a> Camera Culture Group on using reinforcement learning to automate imaging system design,</li>
                  <li>Prof. <a href="https://people.csail.mit.edu/pulkitag/">Pulkit Agrawal's</a> Improbable AI lab on reinforcement learning algorithms.</li>
                </ul>
      
                <p>During high school, I represented India at the <a href="https://www.imo-official.org/participant_r.aspx?id=29103">International Mathematical Olympiad 2019</a> and won a silver medal. In free time, I like to play badminton and read.</p>
  
                <p style="text-align:center">
                  <a href="mailto:bbagrawa@andrew.cmu.edu">Email</a> &nbsp;/&nbsp;
                  <a href="new_data/Bhavya_CV_Quad_Fellowship (1).pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=TdJ4Rk4AAAAJ&hl=en">Google Scholar</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="new_images/prof_pic_circle.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="new_images/prof_pic_circle.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
         
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications and Preprints</h2>
                <p>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr onmouseout="floq_stop()" onmouseover="floq_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='hdlsgd_image'><video  width=100% height=100% muted autoplay loop>
            <source src="new_images/floq.png.jpeg" type="image/png">
            Your browser does not support the video tag.
            </video></div>
            <img src='new_images/floq.png.jpeg' width="160">
          </div>
          <script type="text/javascript">
            function floq_start() {
              document.getElementById('hdlsgd_image').style.opacity = "1";
            }

            function floq_stop() {
              document.getElementById('hdlsgd_image').style.opacity = "0";
            }
            hdlsgd_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2509.06863">
            <span class="papertitle">floq: Training Critics via  Flow-Matching for Scaling Compute in Value-Based RL</span>
          </a>
          <br>
          <strong>Bhavya Agrawalla</strong>,
          <a href="https://www.linkedin.com/in/michal-nauman/">Michal Nauman</a>,
          <a href="https://khush3.github.io/">Khush Agrawal</a>,
          <a href="https://aviralkumar2907.github.io/">Aviral Kumar</a>
          
          <br>
          <em>Under Review at International Conference on Learning Representations (ICLR)</em>, 2026
          <br>
          <a href="https://arxiv.org/abs/2509.06863">arXiv</a>
          <p></p>
          <p>
          A hallmark of modern large-scale machine learning techniques is the use of training objectives that provide dense supervision to intermediate computations, such as teacher forcing the next token in language models or denoising step-by-step in diffusion models. This enables models to learn complex functions in a generalizable manner. Motivated by this observation, we investigate the benefits of iterative computation for temporal difference (TD) methods in reinforcement learning (RL). Typically they represent value functions in a monolithic fashion, without iterative compute. We introduce floq (flow-matching Q-functions), an approach that parameterizes the Q-function using a velocity field and trains it using techniques from flow-matching, typically used in generative modeling. This velocity field underneath the flow is trained using a TD-learning objective, which bootstraps from values produced by a target velocity field, computed by running multiple steps of numerical integration. Crucially, floq allows for more fine-grained control and scaling of the Q-function capacity than monolithic architectures, by appropriately setting the number of integration steps. Across a suite of challenging offline RL benchmarks and online fine-tuning tasks, floq improves performance by nearly 1.8x. floq scales capacity far better than standard TD-learning architectures, highlighting the potential of iterative computation for value learning.
          </p>
        </td>
      </tr>


            
      <tr onmouseout="hdlsgd_stop()" onmouseover="hdlsgd_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='hdlsgd_image'><video  width=100% height=100% muted autoplay loop>
            <source src="new_images/hdlsgd.png.png" type="image/png">
            Your browser does not support the video tag.
            </video></div>
            <img src='new_images/hdlsgd.png.png' width="160">
          </div>
          <script type="text/javascript">
            function hdlsgd_start() {
              document.getElementById('hdlsgd_image').style.opacity = "1";
            }

            function hdlsgd_stop() {
              document.getElementById('hdlsgd_image').style.opacity = "0";
            }
            hdlsgd_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2510.19734">
            <span class="papertitle">Statistical Inference for Linear Functionals of Online Least-Squares SGD when t >= d^{1 + \delta}</span>
          </a>
          <br>
          <strong>Bhavya Agrawalla</strong>,
          <a href="https://sites.google.com/view/kriznakumar/home">Krishnakumar Balasubramaniam</a>,
          <a href="https://sites.google.com/view/promit-ghosal/home">Promit Ghosal</a>

          <br>
          <em>IEEE Transactions On Information Theory</em>, 2025
          <br>
          <a href="https://arxiv.org/abs/2510.19734">arXiv</a>
          <p></p>
          <p>
          Stochastic Gradient Descent (SGD) has become a cornerstone method in modern data science. However, deploying SGD in high-stakes applications necessitates rigorous quantification of its inherent uncertainty. In this work, we establish \emph{non-asymptotic Berry--Esseen bounds} for linear functionals of online least-squares SGD, thereby providing a Gaussian Central Limit Theorem (CLT) in a \emph{growing-dimensional regime}. Existing approaches to high-dimensional inference for projection parameters, such as~\cite{chang2023inference}, rely on inverting empirical covariance matrices and require at least t>=d^{3/2} iterations to achieve finite-sample Berry--Esseen guarantees, rendering them computationally expensive and restrictive in the allowable dimensional scaling. In contrast, we show that a CLT holds for SGD iterates when the number of iterations grows as t>=d^{1 + \delta} for any \delta>0, significantly extending the dimensional regime permitted by prior works while improving computational efficiency. The proposed online SGD-based procedure operates in O(td) time and requires only O(d) memory, in contrast to the O(td^2 + d^3) runtime of covariance-inversion methods.  To render the theory practically applicable, we further develop an \emph{online variance estimator} for the asymptotic variance appearing in the CLT and establish \emph{high-probability deviation bounds} for this estimator. Collectively, these results yield the first fully online and data-driven framework for constructing confidence intervals for SGD iterates in the near-optimal scaling regime t>=d^{1 + \delta}. 
          </p>
        </td>
      </tr>

      <tr onmouseout="diser_stop()" onmouseover="diser_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='diser_image'><video  width=100% height=100% muted autoplay loop>
            <source src="new_images/diser.png" type="image/png">
            Your browser does not support the video tag.
            </video></div>
            <img src='new_images/diser.png' width="160">
          </div>
          <script type="text/javascript">
            function diser_start() {
              document.getElementById('diser_image').style.opacity = "1";
            }

            function diser_stop() {
              document.getElementById('diser_image').style.opacity = "0";
            }
            diser_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2309.13851">
            <span class="papertitle">DISeR: Designing Imaging Systems with Reinforcement Learning</span>
          </a>
          <br>
          <a href="https://tzofi.github.io/">Tzofi Klinghoffer</a>,
          <a href="https://www.media.mit.edu/people/ktiwary/overview/">Kushagra Tiwary</a>,
          <a>Nikhil Behari</a>,
          <strong>Bhavya Agrawalla</strong>,
          <a href="https://www.media.mit.edu/people/raskar/overview/">Ramesh Raskar</a>
          <br>
          <em>International Conference on Computer Vision (ICCV)</em>, 2023
          <br>
          <a href="https://arxiv.org/abs/2309.13851">arXiv</a>
          <p></p>
          <p>
            Imaging systems consist of cameras to encode visual information about the world and perception models to interpret this encoding. Cameras contain (1) illumination sources, (2) optical elements, and (3) sensors, while perception models use (4) algorithms. Directly searching over all combinations of these four building blocks to design an imaging system is challenging due to the size of the search space. Moreover, cameras and perception models are often designed independently, leading to sub-optimal task performance. In this paper, we formulate these four building blocks of imaging systems as a context-free grammar (CFG), which can be automatically searched over with a learned camera designer to jointly optimize the imaging system with task-specific perception models. By transforming the CFG to a state-action space, we then show how the camera designer can be implemented with reinforcement learning to intelligently search over the combinatorial space of possible imaging system configurations. We demonstrate our approach on two tasks, depth estimation and camera rig design for autonomous vehicles, showing that our method yields rigs that outperform industry-wide standards. We believe that our proposed approach is an important step towards automating imaging system design.
          </p>
        </td>
      </tr>
      <tr onmouseout="cohomology_stop()" onmouseover="cohomology_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='cohomology_image'><video  width=100% height=100% muted autoplay loop>
            <source src="new_images/cohomology_image.png" type="image/png">
            Your browser does not support the video tag.
            </video></div>
            <img src='new_images/cohomology_image.png' width="160">
          </div>
          <script type="text/javascript">
            function cohomology_start() {
              document.getElementById('cohomology_image').style.opacity = "1";
            }

            function cohomology_stop() {
              document.getElementById('cohomology_image').style.opacity = "0";
            }
            cohomology_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2211.01536">
            <span class="papertitle">Harrison homology and the Quillen cohomology of commutative monoids</span>
          </a>
          <br>
          <strong>Bhavya Agrawalla</strong>,
          <a>Nasief Khlaif</a>,
          <a href="https://math.mit.edu/~hrm/">Haynes Miller</a>

          <br>
          <em>Semigroup Forum Journal</em>, 2023
          <br>
          <a href="https://arxiv.org/abs/2211.01536">arXiv</a>
          <p></p>
          <p>
          We observe that Beck modules for a commutative monoid are exactly modules over a graded commutative ring associated to the monoid. Under this identification, the Quillen cohomology of commutative monoids is a special case of Andre-Quillen cohomology for graded commutative rings, generalizing a result of Kurdiani and Pirashvili. To verify this we develop the necessary grading formalism. The partial cochain complex developed by Pierre Grillet appears as the start of a modification of the Harrison cochain complex suggested by Michael Barr. We show that Harrison and Quillen cohomology coincide rationally, and thereby establish a cochain complex computing the rational cohomology of a commutative monoid.
          </p>
        </td>
      </tr>
            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
